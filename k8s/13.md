# Stateful Sets

I renamed the `deployment.yaml` to [statefulset.yaml](./chart-msc-time/templates/statefulset.yaml) and changed the `kind` from `Deployment` to `StatefulSet`

The `helm install --dry-run --debug control ./chart-msc-time` command returned compiled configurations - no errors occur.  

Also, I moved configurations about Docker volume for common visits logs to `commonVisits` attribute in [values.yaml](./chart-msc-time/values.yaml).  
To show the uniqueness of pods, I needed to disable the `visit-logs` volume via `commonVisits.enabled` variable.

## Results

```sh
$ kubectl get po,sts,svc,pvc
NAME                READY   STATUS    RESTARTS   AGE
pod/msc-time-py-0   1/1     Running   0          92s
pod/msc-time-py-1   1/1     Running   0          87s
pod/msc-time-py-2   1/1     Running   0          82s

NAME                           READY   AGE
statefulset.apps/msc-time-py   3/3     92s

NAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes    ClusterIP      10.96.0.1       <none>        443/TCP        28d
service/msc-time-py   LoadBalancer   10.105.130.85   <pending>     80:31612/TCP   92s
```

With the use of `minikube service msc-time-py` and several tabs with our app opened, we can notice some differences in `visits`. It can be clearly observed by comparion of `kubectl exec <pod_name> -- cat /app/visits/visits.txt` on different pods:

To show only users requests without the probes (which can disturb us in this tasks), I created new attribute `healthcheck` with `enabled` and `period` parameters, and then disabled it.

<details>
    <summary> pod/msc-time-py-0 </summary>

    20:15:36 - 172.17.0.1
    20:15:39 - 172.17.0.1
    20:15:44 - 172.17.0.1
    20:15:48 - 172.17.0.1
    20:15:58 - 172.17.0.1
    20:16:07 - 172.17.0.1
</details>

<details>
    <summary> pod/msc-time-py-1 </summary>

    20:15:51 - 172.17.0.1
    20:16:04 - 172.17.0.1
</details>

<details>
    <summary> pod/msc-time-py-2 </summary>

    20:15:54 - 172.17.0.1
    20:16:00 - 172.17.0.1
</details>  

As we can see, each of the pods has unique visits history. First pod exists longer then others, that is why it already accepted more requests. 

We do not need to guarantee the state in our application because of only 1 state used for business logic. The only difference is in visits logs, that are useful only for debugging purposes.

## Work with Pods in parallel

To enable work with all pods in parallel rather than sequentially, we need to introduce the `podManagementPolicy: "Parallel"` setting in `spec` attribute.

For this I added this block in `spec`...
```yaml
  {{- if .Values.statefulSet.parallel }}
  podManagementPolicy: "Parallel"
  {{- end }}
```
... and added new variable `statefulSet.parallel` in [values.yaml](./chart-msc-time/values.yaml):
```yaml
statefulSet:
  parallel: true
``` 

We can see the success of parallel setting by the equal live time for all pods:
```sh
$ kubectl get po
NAME                READY   STATUS    RESTARTS   AGE
pod/msc-time-py-0   1/1     Running   0          15s
pod/msc-time-py-1   1/1     Running   0          15s
pod/msc-time-py-2   1/1     Running   0          15s
```

## Bonus:

StatefulSets has 2 strategies for updates: `RollingUpdate` and `OnDelete`.

**RollingUpdate** updates the configuration of pods starting from the newest ones and try to save the state for each of them. This strategy is applied by default.

In **OnDelete** strategy we can delete Pods and StatefulSet simultaneously or separately. In this approach we delete the old configurated pods with thier state and create clear new ones.
